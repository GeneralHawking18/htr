optimizer:
    type: adam
    lr: 0.45
    betas: [0.9, 0.98]
    eps: 1e-9
    weight_decay: 0.01
    lr_mul: 0.5
    n_warm_steps: 25000
    n_steps: 684 * 31 # 684 * (48 + 100)
        
OneCycleLR:
    _target_: torch.optim.lr_scheduler.OneCycleLR
    pct_start: 0.02
    max_lr: 4e-4
    div_factor: 60 # min_lr = max_lr / div_factor
    final_div_factor: 1e3
    three_phase: True

CyclicLR:
    _target_: torch.optim.lr_scheduler.CyclicLR
    base_lr: 5.0e-9
    max_lr: 6.0e-4
    base_momentum: 0.85
    max_momentum: 0.95
    scale_mode: 'iterations'
    mode: 'exp_range'
    gamma: 1 - 4e-4
    step_size_up: 2
    step_size_down: 98
    cycle_momentum: false
# CyclicLR:
    
